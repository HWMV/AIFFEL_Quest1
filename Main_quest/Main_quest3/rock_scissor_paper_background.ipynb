{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HWMV/AIFFEL_Quest1/blob/master/Main_quest/Main_quest3/rock_scissor_paper_background.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main_quest3\n",
        "# rock_scissor_paper\n",
        "# 온라인 6기 코어 최현우\n",
        "\n",
        "* **루브릭**\n",
        "1. 이미지 분류기 모델이 성공적으로 만들어졌는가?\t학습과정이 정상적으로 수행되었으며, 학습 결과에 대한 그래프를 시각화(ex. train acc / train loss / val acc / val loss 등) 해 보았음\n",
        "2. 오버피팅을 극복하기 위한 적절한 시도가 있었는가?\t오버피팅 극복을 위하여 데이터셋의 다양성, 정규화 등을 2가지 이상 시도해보았음\n",
        "3. 분류모델의 test accuracy가 기준 이상 높게 나왔는가?\t85% 이상 도달하였음"
      ],
      "metadata": {
        "id": "kOUjIoJbo0on"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 호출\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)\n",
        "print(np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3cUE8oyrZ1Z",
        "outputId": "6f267803-072d-40cc-b71f-d9ad8be9db55"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n",
            "1.23.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기 (로컬, 구글드라이브 마운트)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2JDTWxeo08I",
        "outputId": "37c2b635-637f-4bc8-aff2-347bdb7d268c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "import os"
      ],
      "metadata": {
        "id": "XHNfgavkvQbu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기2\n",
        "BASE_PATH = \"/content/drive/MyDrive/Main_quest3/\""
      ],
      "metadata": {
        "id": "jaxZ-vSasq6o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paper 이미지 resize 하기 (28x28)(좀 크게 늘려보는중)\n",
        "def resize_images(img_path):\n",
        "    images=glob.glob(img_path + \"/*.jpg\")\n",
        "\n",
        "    print(len(images), \" images to be resized.\")\n",
        "\n",
        "    # 28 x 28 size 로 resize (128 x 128로 해보자. 피처를 추출을 못하는 것 같아!)\n",
        "    target_size=(64,64)\n",
        "    for img in images:\n",
        "        old_img=Image.open(img)\n",
        "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
        "        new_img.save(img, \"JPEG\")\n",
        "\n",
        "    print(len(images), \" images resized.\")\n",
        "\n",
        "# 함수 이용해서 가위바위보 이미지 전부 resize\n",
        "resize_images(BASE_PATH + \"rock\")\n",
        "resize_images(BASE_PATH + \"scissor\")\n",
        "resize_images(BASE_PATH + \"paper\")\n",
        "\n",
        "print(\"resize 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgo3Iyq0u3NI",
        "outputId": "36041e1f-466c-478e-bd92-9fed2090235c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1247  images to be resized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-246436236657>:11: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  new_img=old_img.resize(target_size,Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1247  images resized.\n",
            "1208  images to be resized.\n",
            "1208  images resized.\n",
            "1284  images to be resized.\n",
            "1284  images resized.\n",
            "resize 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load_data 함수 만들기 (노드 참조)\n",
        "\n",
        "def load_data(img_path, number_of_data=3851):\n",
        "    img_size=64\n",
        "    color=3\n",
        "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
        "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
        "\n",
        "    idx=0\n",
        "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img\n",
        "        labels[idx]=0\n",
        "        idx=idx+1\n",
        "\n",
        "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img\n",
        "        labels[idx]=1\n",
        "        idx=idx+1\n",
        "\n",
        "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img\n",
        "        labels[idx]=2\n",
        "        idx=idx+1\n",
        "\n",
        "    print(\"Number of images:\", idx)\n",
        "    return imgs, labels"
      ],
      "metadata": {
        "id": "PZ5acpPhwXe9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_load_data 함수\n",
        "def test_load_data(img_path, number_of_data=441):\n",
        "    img_size=64\n",
        "    color=3\n",
        "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
        "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
        "\n",
        "    idx=0\n",
        "    for file in glob.iglob(img_path+'test/scissor/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img\n",
        "        labels[idx]=0\n",
        "        idx=idx+1\n",
        "\n",
        "    for file in glob.iglob(img_path+'test/rock/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img\n",
        "        labels[idx]=1\n",
        "        idx=idx+1\n",
        "\n",
        "    for file in glob.iglob(img_path+'test/paper/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img\n",
        "        labels[idx]=2\n",
        "        idx=idx+1\n",
        "\n",
        "    print(\"Number of images:\", idx)\n",
        "    return imgs, labels"
      ],
      "metadata": {
        "id": "eCN_XcLNoYkZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"/content/drive/MyDrive/Main_quest3/rock\"))"
      ],
      "metadata": {
        "id": "s7cbj2nLLLvT",
        "outputId": "46be4061-0d7a-412a-df43-c4fe744c536c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['342.jpg', '127 (1).jpg', '1 (3).jpg', '246.jpg', '269.jpg', '400.jpg', '465.jpg', '233.jpg', '143 (1).jpg', '304.jpg', '408.jpg', '448.jpg', '18 (3).jpg', '204.jpg', '406.jpg', '21 (3).jpg', '4 (3).jpg', '454.jpg', '166 (1).jpg', '422.jpg', '327.jpg', '295.jpg', '197.jpg', '240.jpg', '264.jpg', '220.jpg', '524.jpg', '428.jpg', '374.jpg', '458.jpg', '335.jpg', '81 (3).jpg', '436.jpg', '355.jpg', '501.jpg', '134 (1).jpg', '189.jpg', '452.jpg', '347.jpg', '431.jpg', '369.jpg', '430.jpg', '417.jpg', '349.jpg', '471.jpg', '115 (1).jpg', '201.jpg', '370.jpg', '186.jpg', '236.jpg', '244.jpg', '85 (3).jpg', '396.jpg', '381.jpg', '439.jpg', '126 (1).jpg', '110 (1).jpg', '56 (3).jpg', '361.jpg', '287.jpg', '105 (2).jpg', '113 (1).jpg', '305.jpg', '389.jpg', '52 (3).jpg', '168 (1).jpg', '510.jpg', '6 (3).jpg', '486.jpg', '357.jpg', '412.jpg', '75 (3).jpg', '251.jpg', '445.jpg', '245.jpg', '124 (1).jpg', '25 (3).jpg', '483.jpg', '26 복사본.jpg', '62.jpg', '38 복사본 3.jpg', '49 복사본 2.jpg', '21 복사본.jpg', '74.jpg', '175.jpg', '41 복사본 3.jpg', '74 복사본.jpg', '0 복사본 3.jpg', '106 복사본.jpg', '30 복사본 3.jpg', '25 복사본 3.jpg', '53 복사본 2.jpg', '46 복사본 2.jpg', '73 복사본.jpg', '161.jpg', '54 복사본 3.jpg', '60.jpg', '17 복사본.jpg', '149.jpg', '37 복사본 2.jpg', '22 복사본 2.jpg', '42 복사본.jpg', '163.jpg', '7 복사본 3.jpg', '45 복사본.jpg', '10 복사본.jpg', '57 복사본.jpg', '114 복사본.jpg', '7 복사본 2.jpg', '101 복사본.jpg', '177.jpg', '77.jpg', '89.jpg', '162.jpg', '88.jpg', '22 복사본 3.jpg', '37 복사본 3.jpg', '56 복사본.jpg', '176.jpg', '46 복사본 3.jpg', '171.jpg', '48 복사본 2.jpg', '40 복사본 3.jpg', '48 복사본 3.jpg', '40 복사본 2.jpg', '55 복사본 2.jpg', '24 복사본 3.jpg', '115 복사본.jpg', '55 복사본 3.jpg', '31 복사본 3.jpg', '100 복사본.jpg', '39 복사본 2.jpg', '43 복사본.jpg', '158.jpg', '107 복사본.jpg', '164.jpg', '16 복사본.jpg', '44 복사본.jpg', '39 복사본 3.jpg', '31 복사본 2.jpg', '24 복사본 2.jpg', '71.jpg', '9 복사본 3.jpg', '170.jpg', '65.jpg', '59.jpg', '11 복사본.jpg', '148.jpg', '49.jpg', '61.jpg', '174.jpg', '1 복사본 2.jpg', '99 복사본.jpg', '75.jpg', '0 복사본 2.jpg', '33 복사본.jpg', '66 복사본.jpg', '160.jpg', '3 복사본.jpg', '4 복사본.jpg', '49 복사본 3.jpg', '8 복사본 3.jpg', '34 복사본.jpg', '54 복사본 2.jpg', '30 복사본 2.jpg', '67.jpg', '73.jpg', '98.jpg', '93 복사본.jpg', '122.jpg', '62 복사본 2.jpg', '13 복사본 2.jpg', '18 복사본.jpg', '77 복사본 3.jpg', '62 복사본 3.jpg', '77 복사본 2.jpg', '46 (2).jpg', '42 (2).jpg', '49 (2).jpg', '47 (2).jpg', '48 (2).jpg', '40 (2).jpg', '41 (2).jpg', '43 (2).jpg', '44 (2).jpg', '26 (2).jpg', '45 (2).jpg', '27 (2).jpg', '21 (2).jpg', '22 (2).jpg', '20 (2).jpg', '23 (2).jpg', '25 (2).jpg', '24 (2).jpg', '17 (2).jpg', '18 (2).jpg', '14 (2).jpg', '19 (2).jpg', '10 (2).jpg', '11 (2).jpg', '13 (2).jpg', '12 (2).jpg', '16 (2).jpg', '0 (2).jpg', '9 (2).jpg', '15 (2).jpg', '7 (2).jpg', '6 (2).jpg', '2 (2).jpg', '3 (2).jpg', '8 (2).jpg', '57 (2).jpg', '4 (2).jpg', '1 (2).jpg', '59 (2).jpg', '52 (2).jpg', '58 (2).jpg', '38 (2).jpg', '115.jpg', '36 복사본 3.jpg', '9.jpg', '28.jpg', '14.jpg', '23 복사본 3.jpg', '166.jpg', '101.jpg', '60 복사본.jpg', '6 복사본 3.jpg', '172.jpg', '27 복사본.jpg', '75 복사본.jpg', '35 복사본.jpg', '72 복사본.jpg', '20 복사본.jpg', '67 복사본.jpg', '52 복사본 3.jpg', '47 복사본 3.jpg', '52 복사본 2.jpg', '173.jpg', '98 복사본.jpg', '167.jpg', '99.jpg', '2 복사본.jpg', '47 복사본 2.jpg', '5 복사본.jpg', '66.jpg', '6 복사본 2.jpg', '32 복사본.jpg', '72.jpg', '129.jpg', '23 복사본 2.jpg', '112 복사본.jpg', '70.jpg', '58.jpg', '36 복사본 2.jpg', '8.jpg', '9 복사본 2.jpg', '64.jpg', '32 복사본 3.jpg', '165.jpg', '51 복사본.jpg', '1 복사본 3.jpg', '159.jpg', '113.jpg', '57 복사본 3.jpg', '27 복사본 3.jpg', '12.jpg', '33 복사본 3.jpg', '117.jpg', '103.jpg', '49 복사본.jpg', '83 (3).jpg', '155 (1).jpg', '409.jpg', '527.jpg', '288.jpg', '5 (3).jpg', '429.jpg', '120 (1).jpg', '391.jpg', '175 (1).jpg', '482.jpg', '456.jpg', '296.jpg', '61 (3).jpg', '146 (1).jpg', '190.jpg', '248.jpg', '147 (1).jpg', '156 (1).jpg', '461.jpg', '509.jpg', '231.jpg', '161 (1).jpg', '487.jpg', '334.jpg', '167 (1).jpg', '152 (1).jpg', '512.jpg', '107 (2).jpg', '36 (3).jpg', '145 (1).jpg', '27 (3).jpg', '353.jpg', '392.jpg', '484.jpg', '108 (2).jpg', '362.jpg', '438.jpg', '223.jpg', '49 (3).jpg', '354.jpg', '2 (3).jpg', '69 (3).jpg', '423.jpg', '268.jpg', '32 (3).jpg', '232.jpg', '338.jpg', '139 (1).jpg', '100 (2).jpg', '536.jpg', '358.jpg', '19 (3).jpg', '88 (3).jpg', '485.jpg', '324.jpg', '133 (1).jpg', '241.jpg', '351.jpg', '187.jpg', '518.jpg', '35 (3).jpg', '379.jpg', '132 (1).jpg', '418.jpg', '165 (1).jpg', '23 (3).jpg', '481.jpg', '123 (1).jpg', '229.jpg', '28 (3).jpg', '64 (3).jpg', '366.jpg', '140 (1).jpg', '446.jpg', '153 (1).jpg', '67 (3).jpg', '479.jpg', '455.jpg', '212.jpg', '170 (1).jpg', '378.jpg', '218.jpg', '426.jpg', '270.jpg', '497.jpg', '193.jpg', '13 복사본 3.jpg', '330.jpg', '516.jpg', '58 복사본.jpg', '88 복사본 2.jpg', '281.jpg', '453.jpg', '203.jpg', '255.jpg', '317.jpg', '271.jpg', '237.jpg', '82 (3).jpg', '221.jpg', '411.jpg', '277.jpg', '345.jpg', '280.jpg', '467.jpg', '215.jpg', '312.jpg', '332.jpg', '290.jpg', '535.jpg', '206.jpg', '385.jpg', '433.jpg', '340.jpg', '348.jpg', '360.jpg', '424.jpg', '530.jpg', '195.jpg', '495.jpg', '291.jpg', '300.jpg', '196.jpg', '474.jpg', '513.jpg', '192.jpg', '420.jpg', '419.jpg', '174 (1).jpg', '273.jpg', '447.jpg', '31 (3).jpg', '112 (1).jpg', '297.jpg', '320.jpg', '227.jpg', '48 (3).jpg', '350.jpg', '149 (1).jpg', '260.jpg', '224.jpg', '341.jpg', '102 (2).jpg', '528.jpg', '371.jpg', '520.jpg', '29 (3).jpg', '286.jpg', '26 (3).jpg', '184.jpg', '440.jpg', '238.jpg', '76 (3).jpg', '24 (3).jpg', '514.jpg', '282.jpg', '254.jpg', '16 (3).jpg', '519.jpg', '235.jpg', '460.jpg', '494.jpg', '111 (1).jpg', '72 (3).jpg', '96 (3).jpg', '89 (3).jpg', '503.jpg', '526.jpg', '263.jpg', '39 (3).jpg', '77 (3).jpg', '137 (1).jpg', '308.jpg', '459.jpg', '121 (1).jpg', '66 (3).jpg', '158 (1).jpg', '114 (1).jpg', '178 (1).jpg', '343.jpg', '492.jpg', '367.jpg', '135 (1).jpg', '97 (3).jpg', '116 (1).jpg', '306.jpg', '488.jpg', '496.jpg', '507.jpg', '130 (1).jpg', '322.jpg', '252.jpg', '50 복사본.jpg', '8 복사본 2.jpg', '94 (3).jpg', '61 복사본.jpg', '63.jpg', '113 복사본.jpg', '53 복사본 3.jpg', '41 복사본 2.jpg', '38 복사본 2.jpg', '59 복사본 2.jpg', '25 복사본 2.jpg', '76.jpg', '138.jpg', '48.jpg', '28 복사본 2.jpg', '104.jpg', '20 복사본 3.jpg', '32 복사본 2.jpg', '44 복사본 3.jpg', '48 복사본.jpg', '13.jpg', '79 복사본.jpg', '51 복사본 3.jpg', '59 복사본 3.jpg', '86 복사본.jpg', '2 복사본 2.jpg', '39.jpg', '35 복사본 3.jpg', '11.jpg', '106.jpg', '112.jpg', '9 복사본.jpg', '27 복사본 2.jpg', '81 복사본.jpg', '43 복사본 2.jpg', '5 복사본 3.jpg', '56 복사본 2.jpg', '43 복사본 3.jpg', '107.jpg', '39 복사본.jpg', '94 복사본.jpg', '95 복사본 3.jpg', '2 복사본 3.jpg', '56 복사본 3.jpg', '51 (2).jpg', '272.jpg', '53 (2).jpg', '55 (2).jpg', '54 (2).jpg', '50 (2).jpg', '56 (2).jpg', '34 (2).jpg', '30 (2).jpg', '39 (2).jpg', '33 (2).jpg', '31 (2).jpg', '32 (2).jpg', '36 (2).jpg', '37 (2).jpg', '35 (2).jpg', '29 (2).jpg', '79 (2).jpg', '70 (2).jpg', '28 (2).jpg', '85 (2).jpg', '74 (2).jpg', '77 (2).jpg', '71 (2).jpg', '72 (2).jpg', '73 (2).jpg', '75 (2).jpg', '68 (2).jpg', '76 (2).jpg', '78 (2).jpg', '69 (2).jpg', '66 (2).jpg', '60 (2).jpg', '63 (2).jpg', '67 (2).jpg', '64 (2).jpg', '61 (2).jpg', '62 (2).jpg', '65 (2).jpg', '105 (1).jpg', '106 (1).jpg', '108 (1).jpg', '100 (1).jpg', '107 (1).jpg', '102 (1).jpg', '104 (1).jpg', '101 (1).jpg', '99 (2).jpg', '97 (2).jpg', '96 (2).jpg', '103 (1).jpg', '90 (2).jpg', '92 (2).jpg', '98 (2).jpg', '89 (2).jpg', '93 (2).jpg', '95 (2).jpg', '88 (2).jpg', '86 (2).jpg', '91 (2).jpg', '94 (2).jpg', '83 (2).jpg', '109 (1).jpg', '81 (2).jpg', '80 (2).jpg', '82 (2).jpg', '84 (2).jpg', '256.jpg', '407.jpg', '87 (2).jpg', '450.jpg', '37 (3).jpg', '141 (1).jpg', '58 (3).jpg', '432.jpg', '284.jpg', '199.jpg', '144 (1).jpg', '337.jpg', '51 (3).jpg', '12 (3).jpg', '303.jpg', '160 (1).jpg', '261.jpg', '387.jpg', '54 (3).jpg', '247.jpg', '219.jpg', '529.jpg', '523.jpg', '213.jpg', '142 (1).jpg', '181.jpg', '17 (3).jpg', '319.jpg', '444.jpg', '169 (1).jpg', '333.jpg', '435.jpg', '41 (3).jpg', '462.jpg', '228.jpg', '359.jpg', '125 (1).jpg', '283.jpg', '103 (2).jpg', '138 (1).jpg', '506.jpg', '33 (3).jpg', '30 (3).jpg', '515.jpg', '210.jpg', '191.jpg', '372.jpg', '177 (1).jpg', '504.jpg', '225.jpg', '84 (3).jpg', '106 (2).jpg', '368.jpg', '442.jpg', '318.jpg', '478.jpg', '150 (1).jpg', '314.jpg', '176 (1).jpg', '466.jpg', '365.jpg', '469.jpg', '93 (3).jpg', '159 (1).jpg', '313.jpg', '441.jpg', '316.jpg', '377.jpg', '98 (3).jpg', '163 (1).jpg', '525.jpg', '472.jpg', '249.jpg', '457.jpg', '437.jpg', '60 (3).jpg', '498.jpg', '267.jpg', '416.jpg', '388.jpg', '505.jpg', '122 (1).jpg', '356.jpg', '384.jpg', '475.jpg', '70 (3).jpg', '480.jpg', '259.jpg', '95 (3).jpg', '285.jpg', '532.jpg', '470.jpg', '9 (3).jpg', '473.jpg', '13 (3).jpg', '294.jpg', '331.jpg', '148 (1).jpg', '38 (3).jpg', '222.jpg', '185.jpg', '405.jpg', '489.jpg', '383.jpg', '70 복사본 3.jpg', '29 복사본.jpg', '78 복사본 3.jpg', '14 복사본 3.jpg', '78 복사본 2.jpg', '65 복사본 3.jpg', '134.jpg', '96 복사본.jpg', '21.jpg', '108.jpg', '87 복사본 2.jpg', '93 복사본 3.jpg', '92 복사본 2.jpg', '120.jpg', '35.jpg', '64 복사본 2.jpg', '19 복사본.jpg', '15 복사본 3.jpg', '108 복사본.jpg', '59 복사본.jpg', '119.jpg', '86 복사본 3.jpg', '79 복사본 3.jpg', '18.jpg', '15 복사본 2.jpg', '32.jpg', '127.jpg', '24.jpg', '131.jpg', '26.jpg', '125.jpg', '71 복사본 2.jpg', '63 복사본 3.jpg', '133.jpg', '76 복사본 2.jpg', '30.jpg', '68 복사본.jpg', '89 복사본 2.jpg', '76 복사본 3.jpg', '16.jpg', '118 복사본.jpg', '3 복사본 2.jpg', '15.jpg', '42 복사본 3.jpg', '17.jpg', '26 복사본 3.jpg', '102.jpg', '3 복사본 3.jpg', '42 복사본 2.jpg', '33 복사본 2.jpg', '38 복사본.jpg', '116.jpg', '57 복사본 2.jpg', '128.jpg', '29.jpg', '50 복사본 3.jpg', '26 복사본 2.jpg', '92 복사본.jpg', '45 복사본 3.jpg', '114.jpg', '95 복사본.jpg', '100.jpg', '34 복사본 3.jpg', '58 복사본 2.jpg', '4 복사본 3.jpg', '21 복사본 3.jpg', '8 복사본.jpg', '45 복사본 2.jpg', '78 복사본.jpg', '29 복사본 2.jpg', '58 복사본 3.jpg', '50 복사본 2.jpg', '34 복사본 2.jpg', '21 복사본 2.jpg', '80 복사본.jpg', '4 복사본 2.jpg', '87 복사본.jpg', '29 복사본 3.jpg', '69 복사본.jpg', '38.jpg', '44 복사본 2.jpg', '51 복사본 2.jpg', '111.jpg', '20 복사본 2.jpg', '10.jpg', '139.jpg', '105.jpg', '28 복사본 3.jpg', '35 복사본 2.jpg', '5 복사본 2.jpg', '119 복사본.jpg', '110.jpg', '72 (1).jpg', '22 (1).jpg', '70 (1).jpg', '71 (1).jpg', '75 (1).jpg', '69 (1).jpg', '66 (1).jpg', '74 (1).jpg', '67 (1).jpg', '61 (1).jpg', '68 (1).jpg', '62 (1).jpg', '64 (1).jpg', '65 (1).jpg', '97 (1).jpg', '63 (1).jpg', '59 (1).jpg', '91 (1).jpg', '93 (1).jpg', '60 (1).jpg', '92 (1).jpg', '90 (1).jpg', '95 (1).jpg', '99 (1).jpg', '96 (1).jpg', '81 (1).jpg', '98 (1).jpg', '84 (1).jpg', '83 (1).jpg', '80 (1).jpg', '94 (1).jpg', '88 (1).jpg', '82 (1).jpg', '89 (1).jpg', '87 (1).jpg', '86 (1).jpg', '5 (2).jpg', '298.jpg', '198.jpg', '258.jpg', '99 (3).jpg', '10 (3).jpg', '299.jpg', '40 (3).jpg', '91 (3).jpg', '373.jpg', '78 (3).jpg', '157 (1).jpg', '410.jpg', '352.jpg', '151 (1).jpg', '508.jpg', '443.jpg', '209.jpg', '311.jpg', '315.jpg', '517.jpg', '59 (3).jpg', '0 (3).jpg', '179 (1).jpg', '493.jpg', '421.jpg', '380.jpg', '173 (1).jpg', '182.jpg', '208.jpg', '398.jpg', '211.jpg', '363.jpg', '42 (3).jpg', '401.jpg', '101 (2).jpg', '243.jpg', '451.jpg', '207.jpg', '302.jpg', '402.jpg', '278.jpg', '183.jpg', '394.jpg', '74 (3).jpg', '390.jpg', '234.jpg', '321.jpg', '274.jpg', '14 (3).jpg', '449.jpg', '404.jpg', '262.jpg', '463.jpg', '522.jpg', '326.jpg', '266.jpg', '20 (3).jpg', '194.jpg', '117 (1).jpg', '3 (3).jpg', '289.jpg', '339.jpg', '164 (1).jpg', '154 (1).jpg', '328.jpg', '118 (1).jpg', '253.jpg', '171 (1).jpg', '205.jpg', '87 (3).jpg', '214.jpg', '226.jpg', '329.jpg', '90 (3).jpg', '44 (3).jpg', '65 (3).jpg', '476.jpg', '521.jpg', '500.jpg', '7 (3).jpg', '162 (1).jpg', '200.jpg', '131 (1).jpg', '50 (3).jpg', '344.jpg', '136 (1).jpg', '43 (3).jpg', '46 (3).jpg', '477.jpg', '109 (2).jpg', '490.jpg', '62 (3).jpg', '8 (3).jpg', '71 (3).jpg', '499.jpg', '86 (3).jpg', '279.jpg', '399.jpg', '397.jpg', '55 (3).jpg', '180.jpg', '307.jpg', '336.jpg', '403.jpg', '511.jpg', '375.jpg', '415.jpg', '129 (1).jpg', '79 (3).jpg', '464.jpg', '386.jpg', '265.jpg', '468.jpg', '250.jpg', '216.jpg', '502.jpg', '64 복사본 3.jpg', '42.jpg', '124.jpg', '93 복사본 2.jpg', '86 복사본 2.jpg', '79 복사본 2.jpg', '118.jpg', '78.jpg', '50.jpg', '44.jpg', '68.jpg', '97.jpg', '83.jpg', '169.jpg', '40.jpg', '54.jpg', '2.jpg', '6.jpg', '65 복사본.jpg', '69 복사본 3.jpg', '155.jpg', '22 복사본.jpg', '96 복사본 2.jpg', '141.jpg', '18 복사본 2.jpg', '61 복사본 2.jpg', '10 복사본 3.jpg', '77 복사본.jpg', '88 복사본.jpg', '69 복사본 2.jpg', '83 복사본 2.jpg', '61 복사본 3.jpg', '25 복사본.jpg', '96 복사본 3.jpg', '74 복사본 3.jpg', '70 복사본.jpg', '0 복사본.jpg', '74 복사본 2.jpg', '10 복사본 2.jpg', '83 복사본 3.jpg', '30 복사본.jpg', '82.jpg', '96.jpg', '140.jpg', '62 복사본.jpg', '7 복사본.jpg', '69.jpg', '41.jpg', '7.jpg', '18 복사본 3.jpg', '168.jpg', '154.jpg', '43.jpg', '76 복사본.jpg', '23 복사본.jpg', '24 복사본.jpg', '89 복사본.jpg', '79.jpg', '84.jpg', '1.jpg', '45.jpg', '53.jpg', '47.jpg', '68 복사본 3.jpg', '3.jpg', '90.jpg', '36.jpg', '95 복사본 2.jpg', '34.jpg', '109.jpg', '136.jpg', '109 복사본.jpg', '80 복사본 2.jpg', '20.jpg', '123.jpg', '137.jpg', '83 복사본.jpg', '22.jpg', '70 복사본 2.jpg', '84 복사본.jpg', '88 복사본 3.jpg', '14 복사본 2.jpg', '121.jpg', '135.jpg', '91 복사본.jpg', '87 복사본 3.jpg', '65 복사본 2.jpg', '92 복사본 3.jpg', '40 (1).jpg', '44 (1).jpg', '45 (1).jpg', '43 (1).jpg', '19 (1).jpg', '25 (1).jpg', '16 (1).jpg', '18 (1).jpg', '14 (1).jpg', '15 (1).jpg', '7 (1).jpg', '13 (1).jpg', '10 (1).jpg', '12 (1).jpg', '3 (1).jpg', '17 (1).jpg', '8 (1).jpg', '9 (1).jpg', '6 (1).jpg', '11 (1).jpg', '2 (1).jpg', '5 (1).jpg', '1 (1).jpg', '4 (1).jpg', '0 (1).jpg', '57 (1).jpg', '50 (1).jpg', '53 (1).jpg', '56 (1).jpg', '58 (1).jpg', '52 (1).jpg', '51 (1).jpg', '54 (1).jpg', '30 (1).jpg', '32 (1).jpg', '33 (1).jpg', '34 (1).jpg', '55 (1).jpg', '39 (1).jpg', '36 (1).jpg', '31 (1).jpg', '37 (1).jpg', '38 (1).jpg', '35 (1).jpg', '27 (1).jpg', '28 (1).jpg', '26 (1).jpg', '20 (1).jpg', '29 (1).jpg', '23 (1).jpg', '24 (1).jpg', '21 (1).jpg', '73 (1).jpg', '76 (1).jpg', '85 (1).jpg', '78 (1).jpg', '97 복사본.jpg', '94 복사본 2.jpg', '77 (1).jpg', '12 복사본 2.jpg', '94 복사본 3.jpg', '79 (1).jpg', '89 복사본 3.jpg', '12 복사본 3.jpg', '90 복사본.jpg', '81 복사본 2.jpg', '63 복사본 2.jpg', '23.jpg', '82 복사본.jpg', '33.jpg', '37.jpg', '81 복사본 3.jpg', '132.jpg', '27.jpg', '126.jpg', '80 복사본 3.jpg', '80.jpg', '85 복사본.jpg', '84 복사본 2.jpg', '94.jpg', '28 복사본.jpg', '54 복사본.jpg', '142.jpg', '5.jpg', '55.jpg', '17 복사본 3.jpg', '99 복사본 3.jpg', '156.jpg', '66 복사본 2.jpg', '91 복사본 2.jpg', '37 복사본.jpg', '57.jpg', '73 복사본 3.jpg', '110 복사본.jpg', '53 복사본.jpg', '13 복사본.jpg', '105 복사본.jpg', '91 복사본 3.jpg', '73 복사본 2.jpg', '17 복사본 2.jpg', '66 복사본 3.jpg', '102 복사본.jpg', '143.jpg', '46 복사본.jpg', '117 복사본.jpg', '84 복사본 3.jpg', '41 복사본.jpg', '81.jpg', '157.jpg', '99 복사본 2.jpg', '95.jpg', '25.jpg', '19.jpg', '14 복사본.jpg', '56.jpg', '31.jpg', '71 복사본 3.jpg', '130.jpg', '4.jpg', '292.jpg', '310.jpg', '393.jpg', '128 (1).jpg', '22 (3).jpg', '47 (3).jpg', '63 (3).jpg', '73 (3).jpg', '325.jpg', '217.jpg', '376.jpg', '425.jpg', '534.jpg', '104 (2).jpg', '309.jpg', '301.jpg', '202.jpg', '414.jpg', '346.jpg', '15 (3).jpg', '323.jpg', '239.jpg', '188.jpg', '276.jpg', '11 (3).jpg', '491.jpg', '172 (1).jpg', '119 (1).jpg', '293.jpg', '53 (3).jpg', '533.jpg', '92 (3).jpg', '68 (3).jpg', '395.jpg', '413.jpg', '57 (3).jpg', '34 (3).jpg', '45 (3).jpg', '531.jpg', '427.jpg', '434.jpg', '382.jpg', '364.jpg', '242.jpg', '230.jpg', '257.jpg', '275.jpg', '80 (3).jpg', '15 복사본.jpg', '86.jpg', '150.jpg', '60 복사본 2.jpg', '103 복사본.jpg', '40 복사본.jpg', '19 복사본 3.jpg', '178.jpg', '104 복사본.jpg', '51.jpg', '75 복사본 2.jpg', '92.jpg', '144.jpg', '47 복사본.jpg', '19 복사본 2.jpg', '97 복사본 3.jpg', '11 복사본 2.jpg', '68 복사본 2.jpg', '52 복사본.jpg', '11 복사본 3.jpg', '82 복사본 2.jpg', '97 복사본 2.jpg', '12 복사본.jpg', '111 복사본.jpg', '82 복사본 3.jpg', '87.jpg', '93.jpg', '151.jpg', '179.jpg', '75 복사본 3.jpg', '147.jpg', '145.jpg', '116 복사본.jpg', '0.jpg', '55 복사본.jpg', '46.jpg', '60 복사본 3.jpg', '6 복사본.jpg', '72 복사본 2.jpg', '52.jpg', '91.jpg', '153.jpg', '90 복사본 3.jpg', '98 복사본 2.jpg', '85 복사본 3.jpg', '85.jpg', '1 복사본.jpg', '67 복사본 2.jpg', '36 복사본.jpg', '16 복사본 2.jpg', '67 복사본 3.jpg', '16 복사본 3.jpg', '152.jpg', '85 복사본 2.jpg', '64 복사본.jpg', '63 복사본.jpg', '71 복사본.jpg', '90 복사본 2.jpg', '72 복사본 3.jpg', '31 복사본.jpg', '98 복사본 3.jpg', '48 (1).jpg', '47 (1).jpg', '146.jpg', '49 (1).jpg', '46 (1).jpg', '41 (1).jpg', '42 (1).jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 흑백 배경 만들기 위한 mask 이미지 생성\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "image_path = BASE_PATH + 'rock'\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "if image is None:\n",
        "    print(f\"Error loading image: {image_path}\")\n",
        "    sys.exit()\n",
        "\n",
        "def generate_mask(image_path, save_path):\n",
        "    \"\"\"\n",
        "    이미지에서 배경 마스크를 생성하고 저장하는 함수\n",
        "\n",
        "    :param image_path: 마스크를 생성할 원본 이미지의 경로\n",
        "    :param save_path: 생성된 마스크를 저장할 경로\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "\n",
        "    # 이미지 불러오기\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # 이미지를 그레이스케일로 변환\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 이진화\n",
        "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # 노이즈 제거를 위한 모폴로지 연산\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
        "    cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # 마스크 저장\n",
        "    cv2.imwrite(save_path, cleaned)\n",
        "\n",
        "def generate_mask_for_all_images(base_image_path, save_directory):\n",
        "    \"\"\"\n",
        "    디렉터리 내의 모든 이미지에 대해 마스크를 생성하고 저장합니다.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(save_directory):\n",
        "        os.makedirs(save_directory)\n",
        "\n",
        "    # base_image_path 내의 모든 이미지 파일에 대해\n",
        "    for file in os.listdir(base_image_path):\n",
        "        if file.endswith('.jpg'):  # jpg 이미지만 처리\n",
        "            image_path = os.path.join(base_image_path, file)\n",
        "            mask_save_path = os.path.join(save_directory, file)\n",
        "\n",
        "            generate_mask(image_path, mask_save_path)  # 위에서 정의한 함수 사용\n",
        "\n",
        "# 사용\n",
        "base_image_path = os.path.join(BASE_PATH, 'rock')\n",
        "save_directory = os.path.join(BASE_PATH, 'Segmentation')\n",
        "generate_mask_for_all_images(base_image_path, save_directory)\n",
        "\n",
        "# 함수 사용\n",
        "generate_mask(BASE_PATH + 'rock', BASE_PATH + 'Segmentation')"
      ],
      "metadata": {
        "id": "phUazNlzFNM4",
        "outputId": "a306d828-3727-4855-b87c-dd7583d017e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading image: /content/drive/MyDrive/Main_quest3/rock\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 흑백 배경으로 데이터 변환 (Image Segmentation)\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Encoding (downsampling)\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', padding='same')(p1)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', padding='same')(p2)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    # Bottleneck\n",
        "    b = Conv2D(128, (3, 3), activation='relu', padding='same')(p3)\n",
        "\n",
        "    # Decoding (upsampling)\n",
        "    u1 = UpSampling2D((2, 2))(b)\n",
        "    merge1 = concatenate([u1, c3])\n",
        "    c4 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge1)\n",
        "\n",
        "    u2 = UpSampling2D((2, 2))(c4)\n",
        "    merge2 = concatenate([u2, c2])\n",
        "    c5 = Conv2D(32, (3, 3), activation='relu', padding='same')(merge2)\n",
        "\n",
        "    u3 = UpSampling2D((2, 2))(c5)\n",
        "    merge3 = concatenate([u3, c1])\n",
        "    c6 = Conv2D(16, (3, 3), activation='relu', padding='same')(merge3)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c6)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Build the U-Net model\n",
        "input_shape = (128, 128, 3)  # Example input shape\n",
        "model = build_unet(input_shape)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "1-TqajXLDkWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_test_split 함수 불러오기\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train data 설정\n",
        "(x_data, y_data) = load_data(BASE_PATH)\n",
        "\n",
        "# Train, Validation 데이터 분리\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=2023)\n",
        "\n",
        "# 데이터 정규화\n",
        "x_train_norm = x_train / 255.0\n",
        "x_val_norm = x_val / 255.0\n",
        "\n",
        "print(\"x_train shape: {}\".format(x_train.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))\n",
        "print(\"x_val shape: {}\".format(x_val.shape))\n",
        "print(\"y_val shape: {}\".format(y_val.shape))"
      ],
      "metadata": {
        "id": "ofHhjgF6L1Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test data\n",
        "# 위 과정 경로만 바꿔서 test data 세팅\n",
        "resize_images(BASE_PATH + \"test/rock\")\n",
        "resize_images(BASE_PATH + \"test/scissor\")\n",
        "resize_images(BASE_PATH + \"test/paper\")\n",
        "(x_test, y_test) = test_load_data(BASE_PATH)\n",
        "x_test_norm = x_test / 255.0\n",
        "\n",
        "print(\"x_test shape: {}\".format(x_test.shape))\n",
        "print(\"y_test shape: {}\".format(y_test.shape))"
      ],
      "metadata": {
        "id": "-RfMFl-iT5iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터들 확인\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x_train[2])\n",
        "print('라벨: ', y_train[2]) # 가위, 실제값 가위"
      ],
      "metadata": {
        "id": "-_wER0Ljd1oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구성하기 Sequestial 모델 사용\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 데이터 증강(ImageDataGenerator() 활용)\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10, # 이미지를 0~10도 사이로 랜덤하게 회전\n",
        "    zoom_range=0.1, # 0.9~1.1 사이로 랜덤하게 확대/축소\n",
        "    width_shift_range=0.1,  # 10% 범위에서 좌/우 이동\n",
        "    height_shift_range=0.1, # 10% 범위에서 상/하 이동\n",
        "    horizontal_flip=True # 좌우 반전\n",
        ")\n",
        "# train data가 너무 오버피팅(과적합) 되어서 처리 해줌\n",
        "datagen.fit(x_train_norm)\n",
        "\n",
        "# Model(Sequential) 구성 (뉴런 수 조절 : 오버피팅 방지)\n",
        "model = Sequential()\n",
        "# Layer 마다 뉴런 수 감소 : 오버피팅 방지\n",
        "model.add(tf.keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=(64,64,3)))\n",
        "model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
        "model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "\n",
        "# 출력층\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "iwLU-on2UCyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 compile 하기\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Early stopping 추가\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7)\n",
        "\n",
        "# 학습 및 검증 실행\n",
        "history = model.fit(datagen.flow(x_train_norm, y_train),\n",
        "                    epochs=15,\n",
        "                    validation_data=(x_val_norm, y_val),\n",
        "                    callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "zU7mBP7Jm8Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation(Train)\n",
        "train_loss, train_accuracy = model.evaluate(x_train_norm, y_train, verbose=2)\n",
        "print(\"train_loss: {} \".format(train_loss))\n",
        "print(\"train_accuracy: {}\".format(train_accuracy))\n",
        "\n",
        "# Model evaluation(Validation)\n",
        "val_loss, val_accuracy = model.evaluate(x_val_norm, y_val, verbose=2)\n",
        "print(\"val_loss: {} \".format(val_loss))\n",
        "print(\"val_accuracy: {}\".format(val_accuracy))\n",
        "\n",
        "# Model evaluation(Test)\n",
        "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
        "print(\"test_loss: {} \".format(test_loss))\n",
        "print(\"test_accuracy: {}\".format(test_accuracy))"
      ],
      "metadata": {
        "id": "NFhkk3leUmPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train and Validation Loss 그래프\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Train and Validation Accuracy 그래프\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QvjGu01PjTwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# 테스트 데이터에서 무작위로 5개의 인덱스를 선택\n",
        "random_indices = random.sample(range(x_test.shape[0]), 5)\n",
        "\n",
        "# 해당 인덱스의 이미지와 라벨 가져오기\n",
        "random_images = x_test[random_indices]\n",
        "random_labels = y_test[random_indices]\n",
        "\n",
        "# 이미지에 대한 예측값 계산\n",
        "predictions = model.predict(random_images)\n",
        "\n",
        "# 예측값에서 가장 높은 확률을 가진 클래스 선택\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# 이미지와 예측값, 실제값 비교하기\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, index in enumerate(random_indices):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.imshow(random_images[i])\n",
        "    plt.title(f\"Predicted: {predicted_labels[i]}, True: {random_labels[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lRuReA7oi7DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **회 고 록**\n",
        "* ## train data의 오버피팅(과적합) 방지를 위한 방법\n",
        "1. 데이터 shuffle 사용해보자 : 데이터 확장, 오버피팅 방지\n",
        "shuffle_data = np.arange(x_train.shape[0])\n",
        "np.random.shuffle(shuffle_data)\n",
        "\n",
        "2. 데이터 증강(ImageDataGenerator(), fit에서 datagen.flow 활용)\n",
        "했었으나 데이터 수를 늘리고 증강을 빼고 성능이 좋아서 삭제 했습니다 (충분히 train data로 학습)\n",
        "데이터 수 회전,확대/축소 등으로 데이터 증강\n",
        "(train data : 300장 > 1200장 > 3851장)\n",
        "(validation data : train data 20%)\n",
        "(test data : 639장)\n",
        "\n",
        "3. 픽셀 정규화\n",
        "x_data_norm = x_data / 255.0\n",
        "x_train_norm = x_train / 255.0\n",
        "x_val_norm = x_val / 255.0\n",
        "x_test_norm = x_test / 255.0\n",
        "\n",
        "4. dropout, BatchNormalization\n",
        "각 layer 사이에 dropout(50%), BatchNormalization 적용\n",
        "(train data가 너무 오버피팅 되서 조절)\n",
        "\n",
        "---\n",
        "* ## test data의 성능 향상을 위한 방법\n",
        "1. epoch 수 증가 (10 > 30)\n",
        "2. 데이터 셔플 제외 라벨 데이트까지 섞여서 확인 시 클래스가 섞여 나오는 것 확인\n",
        "3. 쓸데없이 오버피팅 방지한 것들 제거 중 (dropout, batch normalization 등)\n",
        "4. test data 비율 10~20% 정도로 줄여서 test\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## **배우고 느낀 점**\n",
        "\n",
        "test data를 더 늘리고, train data도 더 늘려서 작업해보고 싶지만 업로드와 epoch의 시간소요에 여기까지만 조절 했습니다\n",
        "\n",
        "fit 학습을 여러번 반복하면 기존 학습에 이어서 학습을 해서 제대로 학습이 안되는 부분도 배웠습니다. 코드를 중복되지 않게 구현 하는 연습도 해봐야 할 것 같다고 생각 했습니다.\n",
        "\n",
        "여러가지로 오버피팅 방지가 어렵고 관건이라고 배웠습니다. 그래도 실험해보면서 바뀌는 모습을 보면서 재밌게 작업했습니다. 여러 시도를 해보기 위해 컴퓨터 사양을 늘려야 효율적일 것 같다고 느꼈습니다.\n",
        "\n",
        "오버피팅의 어려움을 체감하고 오버피팅(과적합) 방지에 여러 방법이 있고, 왜 사용하는지를 정확하게 이해하고 사용해야 된다는 것을 배웠습니다. 시각화의 중요성도 많이 배웠습니다.\n",
        "더욱 정진 하겠습니다.\n",
        "\n",
        "---\n",
        "\n",
        "## **해결 못한 점**\n",
        "1. pred값과 실제값 비교에서 흑백 사진의 정체\n",
        "(해결 : train, test 데이터 load 하는 함수 따로 생성하고 데이터 수를 맞춰 줬습니다)\n",
        "2. test 성능 향상을 마저 못했습니다\n",
        "(가위 클래스 0은 잘 분석하나, 정면 바위 사진을 2(보)로 예측하는 경우가 많았습니다. 한 그루분의 test data가 굉장히 특이한 형태로 만드셨습니다)\n",
        "(학습 데이터에서 특이한 바위와 보 데이터를 더 확보해야 될 것 같다고 분석했습니다)"
      ],
      "metadata": {
        "id": "mqS9L92vePQ1"
      }
    }
  ]
}