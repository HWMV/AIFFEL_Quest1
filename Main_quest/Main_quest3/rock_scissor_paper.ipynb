{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HWMV/AIFFEL_Quest1/blob/master/Main_quest/Main_quest3/rock_scissor_paper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main_quest3\n",
        "# rock_scissor_paper\n",
        "# 온라인 6기 코어 최현우\n",
        "\n",
        "* **루브릭**\n",
        "1. 이미지 분류기 모델이 성공적으로 만들어졌는가?\t학습과정이 정상적으로 수행되었으며, 학습 결과에 대한 그래프를 시각화(ex. train acc / train loss / val acc / val loss 등) 해 보았음\n",
        "2. 오버피팅을 극복하기 위한 적절한 시도가 있었는가?\t오버피팅 극복을 위하여 데이터셋의 다양성, 정규화 등을 2가지 이상 시도해보았음\n",
        "3. 분류모델의 test accuracy가 기준 이상 높게 나왔는가?\t85% 이상 도달하였음"
      ],
      "metadata": {
        "id": "kOUjIoJbo0on"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 호출\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)\n",
        "print(np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3cUE8oyrZ1Z",
        "outputId": "9402197b-3c52-4c77-ad07-57dcdddae099"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n",
            "1.23.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기 (로컬, 구글드라이브 마운트)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2JDTWxeo08I",
        "outputId": "e7ecec7a-d8ed-4ee1-f409-a75c91cfcb74"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "import os"
      ],
      "metadata": {
        "id": "XHNfgavkvQbu"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기2\n",
        "BASE_PATH = \"/content/drive/MyDrive/Main_quest3/\""
      ],
      "metadata": {
        "id": "jaxZ-vSasq6o"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paper 이미지 resize 하기 (28x28)\n",
        "def resize_images(img_path):\n",
        "    images=glob.glob(img_path + \"/*.jpg\")\n",
        "\n",
        "    print(len(images), \" images to be resized.\")\n",
        "\n",
        "    # 28 x 28 size 로 resize\n",
        "    target_size=(28,28)\n",
        "    for img in images:\n",
        "        old_img=Image.open(img)\n",
        "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
        "        new_img.save(img, \"JPEG\")\n",
        "\n",
        "    print(len(images), \" images resized.\")\n",
        "\n",
        "# 함수 이용해서 가위바위보 이미지 전부 resize\n",
        "resize_images(BASE_PATH + \"rock\")\n",
        "resize_images(BASE_PATH + \"scissor\")\n",
        "resize_images(BASE_PATH + \"paper\")\n",
        "\n",
        "print(\"resize 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgo3Iyq0u3NI",
        "outputId": "98477ced-048d-48df-fc08-1832911b845f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1247  images to be resized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-5a0fe5e6b29e>:11: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  new_img=old_img.resize(target_size,Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1247  images resized.\n",
            "1320  images to be resized.\n",
            "1320  images resized.\n",
            "1284  images to be resized.\n",
            "1284  images resized.\n",
            "resize 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load_data 함수 만들기 (노드 참조)\n",
        "\n",
        "def load_data(img_path, number_of_data=3851):\n",
        "    img_size=28\n",
        "    color=3\n",
        "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
        "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
        "\n",
        "    idx=0\n",
        "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img\n",
        "        labels[idx]=0\n",
        "        idx=idx+1\n",
        "\n",
        "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img\n",
        "        labels[idx]=1\n",
        "        idx=idx+1\n",
        "\n",
        "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img\n",
        "        labels[idx]=2\n",
        "        idx=idx+1\n",
        "\n",
        "    print(\"Number of images:\", idx)\n",
        "    return imgs, labels\n",
        "\n",
        "# train data 설정\n",
        "(x_data, y_data) = load_data(BASE_PATH)\n",
        "\n",
        "# 데이터 shuffle 사용해보자 : 데이터 확장, 오버피팅 방지\n",
        "shuffle_data = np.arange(x_data.shape[0])\n",
        "np.random.shuffle(shuffle_data)\n",
        "\n",
        "x_data = x_data[shuffle_data]\n",
        "y_data = y_data[shuffle_data]\n",
        "\n",
        "# 데이터 정규화\n",
        "x_data_norm = x_data / 255.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZ5acpPhwXe9",
        "outputId": "770adf37-edb0-4826-9c15-17dc9c48b5a4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images: 3851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_load_data\n",
        "def test_load_data(img_path, number_of_data=1789):\n",
        "    img_size=28\n",
        "    color=3\n",
        "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
        "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
        "\n",
        "    idx=0\n",
        "    for file in glob.iglob(img_path+'test/scissor/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img\n",
        "        labels[idx]=0\n",
        "        idx=idx+1\n",
        "\n",
        "    for file in glob.iglob(img_path+'test/rock/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img\n",
        "        labels[idx]=1\n",
        "        idx=idx+1\n",
        "\n",
        "    for file in glob.iglob(img_path+'test/paper/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img\n",
        "        labels[idx]=2\n",
        "        idx=idx+1\n",
        "\n",
        "    print(\"Number of images:\", idx)\n",
        "    return imgs, labels"
      ],
      "metadata": {
        "id": "eCN_XcLNoYkZ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_test_split 함수 불러오기\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train, Validation 데이터 분리\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 정규화\n",
        "x_train_norm = x_train / 255.0\n",
        "x_val_norm = x_val / 255.0"
      ],
      "metadata": {
        "id": "ofHhjgF6L1Yl"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test data\n",
        "# 위 과정 경로만 바꿔서 test data 세팅\n",
        "resize_images(BASE_PATH + \"test/rock\")\n",
        "resize_images(BASE_PATH + \"test/scissor\")\n",
        "resize_images(BASE_PATH + \"test/paper\")\n",
        "(x_test, y_test) = test_load_data(BASE_PATH)\n",
        "x_test_norm = x_test / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RfMFl-iT5iI",
        "outputId": "1db3252c-3906-4961-e9e8-d4f1fea79ee6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "540  images to be resized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-5a0fe5e6b29e>:11: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  new_img=old_img.resize(target_size,Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "540  images resized.\n",
            "515  images to be resized.\n",
            "515  images resized.\n",
            "626  images to be resized.\n",
            "626  images resized.\n",
            "Number of images: 1660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구성하기 Sequestial 모델 사용\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 데이터 증강(ImageDataGenerator() 활용)\n",
        "# datagen = ImageDataGenerator(\n",
        "#     rotation_range=10, # 이미지를 0~10도 사이로 랜덤하게 회전\n",
        "#     zoom_range=0.1, # 0.9~1.1 사이로 랜덤하게 확대/축소\n",
        "#     width_shift_range=0.1,  # 10% 범위에서 좌/우 이동\n",
        "#     height_shift_range=0.1, # 10% 범위에서 상/하 이동\n",
        "#     horizontal_flip=True # 좌우 반전\n",
        "# )\n",
        "# # train data가 너무 오버피팅(과적합) 되어서 처리 해줌\n",
        "# datagen.fit(x_train_norm)\n",
        "\n",
        "# Model(Sequential) 구성 (뉴런 수 조절 : 오버피팅 방지)\n",
        "model = Sequential()\n",
        "# Layer 마다 뉴런 수 감소 : 오버피팅 방지\n",
        "model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,3)))\n",
        "# BatchNormalization : 오버피팅 방지\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
        "# Dropout 추가 : 오버피팅 방지 (train data가 너무 잘 적응함) 50%에서 좀 더 방지 위해 60% 했다가 다시 50%!\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Conv2D(16, (3,3), activation='relu'))\n",
        "# BatchNormalization : 오버피팅 방지\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "# Dropout 추가 : 오버피팅 방지 (train data가 너무 잘 적응함)\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "# BatchNormalization : 오버피팅 방지\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "# Dropout 추가 : 오버피팅 방지 (train data가 너무 잘 적응함)\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "# 출력층\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "# 모델 compile 하기\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Early stopping 추가\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7)\n",
        "\n",
        "# 학습 및 검증 실행\n",
        "history = model.fit(x_train_norm, y_train,\n",
        "                    epochs=20,\n",
        "                    validation_data=(x_val_norm, y_val),\n",
        "                    callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwLU-on2UCyG",
        "outputId": "408b4a78-4d7e-4f82-f510-c942b00a32bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "97/97 [==============================] - 7s 54ms/step - loss: 1.4991 - accuracy: 0.3981 - val_loss: 1.1903 - val_accuracy: 0.3502\n",
            "Epoch 2/20\n",
            "15/97 [===>..........................] - ETA: 2s - loss: 1.2599 - accuracy: 0.4417"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation(Train)\n",
        "train_loss, train_accuracy = model.evaluate(x_train_norm, y_train, verbose=2)\n",
        "print(\"train_loss: {} \".format(train_loss))\n",
        "print(\"train_accuracy: {}\".format(train_accuracy))\n",
        "\n",
        "# Model evaluation(Validation)\n",
        "val_loss, val_accuracy = model.evaluate(x_val_norm, y_val, verbose=2)\n",
        "print(\"val_loss: {} \".format(val_loss))\n",
        "print(\"val_accuracy: {}\".format(val_accuracy))\n",
        "\n",
        "# Model evaluation(Test)\n",
        "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
        "print(\"test_loss: {} \".format(test_loss))\n",
        "print(\"test_accuracy: {}\".format(test_accuracy))"
      ],
      "metadata": {
        "id": "NFhkk3leUmPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train and Validation Loss 그래프\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Train and Validation Accuracy 그래프\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QvjGu01PjTwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# 테스트 데이터에서 무작위로 5개의 인덱스를 선택\n",
        "random_indices = random.sample(range(x_test.shape[0]), 5)\n",
        "\n",
        "# 해당 인덱스의 이미지와 라벨 가져오기\n",
        "random_images = x_test[random_indices]\n",
        "random_labels = y_test[random_indices]\n",
        "\n",
        "# 이미지에 대한 예측값 계산\n",
        "predictions = model.predict(random_images)\n",
        "\n",
        "# 예측값에서 가장 높은 확률을 가진 클래스 선택\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# 이미지와 예측값, 실제값 비교하기\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, index in enumerate(random_indices):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.imshow(random_images[i])\n",
        "    plt.title(f\"Predicted: {predicted_labels[i]}, True: {random_labels[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lRuReA7oi7DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **회 고 록**\n",
        "* ## train data의 오버피팅(과적합) 방지를 위한 방법\n",
        "1. 데이터 shuffle 사용해보자 : 데이터 확장, 오버피팅 방지\n",
        "shuffle_data = np.arange(x_train.shape[0])\n",
        "np.random.shuffle(shuffle_data)\n",
        "\n",
        "2. 데이터 증강(ImageDataGenerator(), fit에서 datagen.flow 활용)\n",
        "했었으나 데이터 수를 늘리고 증강을 빼고 성능이 좋아서 삭제 했습니다 (충분히 train data로 학습)\n",
        "데이터 수 회전,확대/축소 등으로 데이터 증강\n",
        "(train data : 300장 > 1200장 > 3851장)\n",
        "(validation data : train data 20%)\n",
        "(test data : 300장 > 1567장, 깨진 데이터 제외하고 965장 > 부족해서 추가 1789장)\n",
        "\n",
        "3. 픽셀 정규화\n",
        "x_data_norm = x_data / 255.0\n",
        "x_train_norm = x_train / 255.0\n",
        "x_val_norm = x_val / 255.0\n",
        "x_test_norm = x_test / 255.0\n",
        "\n",
        "4. dropout, BatchNormalization\n",
        "각 layer 사이에 dropout(50%), BatchNormalization 적용\n",
        "(train data가 너무 오버피팅 되서 조절)\n",
        "\n",
        "5. Layer 뉴런 수 감소 시키기 (128, 64, 32 > 32, 16, 16)\n",
        "\n",
        "6. 실제값과 예측값 비교(test data 랜덤 5개)\n",
        "비교 중 test data 중 못 쓰는 데이터 발견, 선별 후 새로운 데이터로 재구성\n",
        "\n",
        "---\n",
        "\n",
        "## **배우고 느낀 점**\n",
        "\n",
        "test data를 더 늘리고, train data도 더 늘려서 작업해보고 싶지만 업로드와 epoch의 시간소요에 여기까지만 조절 했습니다\n",
        "\n",
        "fit 학습을 여러번 반복하면 기존 학습에 이어서 학습을 해서 제대로 학습이 안되는 부분도 배웠습니다. 코드를 중복되지 않게 구현 하는 연습도 해봐야 할 것 같다고 생각 했습니다.\n",
        "\n",
        "여러가지로 오버피팅 방지가 어렵고 관건이라고 배웠습니다. 그래도 실험해보면서 바뀌는 모습을 보면서 재밌게 작업했습니다. 여러 시도를 해보기 위해 컴퓨터 사양을 늘려야 효율적일 것 같다고 느꼈습니다.\n",
        "\n",
        "오버피팅의 어려움을 체감하고 오버피팅(과적합) 방지에 여러 방법이 있고, 왜 사용하는지를 정확하게 이해하고 사용해야 된다는 것을 배웠습니다. 시각화의 중요성도 많이 배웠습니다.\n",
        "더욱 정진 하겠습니다.\n",
        "\n",
        "---\n",
        "\n",
        "## **해결 못한 점**\n",
        "1. pred값과 실제값 비교에서 흑백 사진의 정체\n",
        "(시각화 부분에서 문제인건지, load_data 부분에서 문제인건지 확인 못했습니다)\n",
        "2. validation의 acc 그래프가 왜 이리 진동 폭이 큰지 확인 못했습니다"
      ],
      "metadata": {
        "id": "mqS9L92vePQ1"
      }
    }
  ]
}